{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-of-Thoughts Interactive Notebook\n",
    "\n",
    "This notebook is an interactive version of the [Tree-of-Thoughts](https://github.com/zbambergerNLP/tree-of-thoughts) library.\n",
    "It allows you to explore [Tree-of-Thoughts](https://arxiv.org/pdf/2305.10601) functionality to create persuasive arguments and engage in debates.\n",
    "\n",
    "![Tree-of-Thoughts](figures/tot_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Tree-of-Thoughts Works\n",
    "\n",
    "Tree-of-Thoughts is a sequential prompting framework that is meant to evoke complex reasoning and planning capabilities in language models. We apply the Tree-of-Thoughts framework to the task of generating persuasive arguments (rather than tasks like `game-of-24`, `crosswords` or `creative writing`, which were used in the original paper).\n",
    "\n",
    "A core idea in Tree-of-Thoughts is iterative expansion of a tree structure. In this tree structure, nodes represent \"thoughts\" ($z_t$), which are textual responses that incorporate intermediate/reasoning steps towards a final response. As part of the tree structure, a \"thought\" in layer `t` creates a set of \"child thoughts\" in layer `t+1`. This is known as the \"branching\" step (by a component known in the original paper as \"Thought Generator\", $G()$). \n",
    "\n",
    "Since unmediated branching can lead to a combinatorial explosion, we use a \"debate judge\" to evaluate the quality of each child thought after each expansion. The \"debate judge\" is a model that scores the quality of a thought based on its quality (a component known in the original paper as \"States Evaluator\", $V()$). Only the top scoring nodes in layer `t+1` are retained for further expansion. This is known as the \"selection\" step. \n",
    "\n",
    "See the full psuedocode excerpt from [Tree-of-Thoughts](https://arxiv.org/pdf/2305.10601) which describes the process:\n",
    "\n",
    "![Tree-of-Thoughts Pseudocode](figures/tot_bfs_pseudocode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Interpretation\n",
    "\n",
    "We interpret the Tree-of-Thoughts framework as a way to generate persuasive arguments. In this notebook we use closed-source language models (`gpt-3.5-turbo`, `gpt-4o`, `gpt-4o-mini`) to serve as both the \"Thought Generator\" and the \"States Evaluator\".\n",
    "\n",
    "Rather than viewing nodes in the tree as \"thoughts\", we view them as \"argument states\" (which can include context about both the existing conversation and previous drafts). The \"thoughts\" in the original paper are meant to be intermediate steps towards a final response. In our case, the \"arguments\" are meant to be intermediate drafts towards a final persuasive argument.\n",
    "\n",
    "### Alternative Interpretations (and why we chose ours instead)\n",
    "\n",
    "While we chose to iterate over drafts at each layer of the tree, it is also possible to consider alternative interpretations of the Tree-of-Thoughts framework:\n",
    "\n",
    "* One could consider each layer of the tree as an \"expansion\" of the argument (i.e., a child node presents an argument that is more detailed than its parent). We chose not to go with this approach because we didn't want the depth of a tree to be directly proportional to the length of the output.\n",
    "\n",
    "* Another alternative interpretation is to consider pre-defined \"instructions\" for each layer of the tree (e.g., the first layer is meant for planning, the second layer is meant for identifying relevant facts, etc...). However, this approach would require a lot of manual work to define the instructions for each layer, and is not necessarily generalizable or scalable.\n",
    "\n",
    "We therefore chose to iterate over drafts at each layer of the tree, as it is a simple and generalizable approach that can be applied to a wide range of argument generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dspy-ai in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.4.13)\n",
      "Requirement already satisfied: openai in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.41.0)\n",
      "Requirement already satisfied: networkx in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: matplotlib in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (3.9.2)\n",
      "Requirement already satisfied: pydot in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: absl-py in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (2.1.0)\n",
      "Requirement already satisfied: pytest in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (8.3.2)\n",
      "Requirement already satisfied: transformers in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (4.44.0)\n",
      "Requirement already satisfied: datasets in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2.21.0)\n",
      "Requirement already satisfied: sentence_transformers in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (3.0.1)\n",
      "Requirement already satisfied: asyncio in ./.env/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (3.4.3)\n",
      "Requirement already satisfied: backoff in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3 in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: optuna in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (3.6.1)\n",
      "Requirement already satisfied: pandas in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: pydantic~=2.0 in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: regex in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (2024.7.24)\n",
      "Requirement already satisfied: requests in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: structlog in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (24.4.0)\n",
      "Requirement already satisfied: tqdm in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (4.66.5)\n",
      "Requirement already satisfied: ujson in ./.env/lib/python3.12/site-packages (from dspy-ai->-r requirements.txt (line 2)) (5.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.env/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.env/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.env/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.env/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: sniffio in ./.env/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.env/lib/python3.12/site-packages (from openai->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.env/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: iniconfig in ./.env/lib/python3.12/site-packages (from pytest->-r requirements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in ./.env/lib/python3.12/site-packages (from pytest->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 15)) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 15)) (0.24.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 15)) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 15)) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 15)) (0.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 16)) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 16)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 16)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./.env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 16)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in ./.env/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->-r requirements.txt (line 16)) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in ./.env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 16)) (3.10.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.env/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 19)) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in ./.env/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 19)) (1.5.1)\n",
      "Requirement already satisfied: scipy in ./.env/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 19)) (1.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.env/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 16)) (2.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 16)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 16)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 16)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 16)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 16)) (1.9.4)\n",
      "Requirement already satisfied: certifi in ./.env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.env/lib/python3.12/site-packages (from pydantic~=2.0->dspy-ai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.env/lib/python3.12/site-packages (from pydantic~=2.0->dspy-ai->-r requirements.txt (line 2)) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env/lib/python3.12/site-packages (from requests->dspy-ai->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.12/site-packages (from requests->dspy-ai->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: sympy in ./.env/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 19)) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 19)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./.env/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 19)) (72.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.env/lib/python3.12/site-packages (from optuna->dspy-ai->-r requirements.txt (line 2)) (1.13.2)\n",
      "Requirement already satisfied: colorlog in ./.env/lib/python3.12/site-packages (from optuna->dspy-ai->-r requirements.txt (line 2)) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./.env/lib/python3.12/site-packages (from optuna->dspy-ai->-r requirements.txt (line 2)) (2.0.32)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.12/site-packages (from pandas->dspy-ai->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.env/lib/python3.12/site-packages (from pandas->dspy-ai->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.env/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 19)) (3.5.0)\n",
      "Requirement already satisfied: Mako in ./.env/lib/python3.12/site-packages (from alembic>=1.5.0->optuna->dspy-ai->-r requirements.txt (line 2)) (1.3.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 19)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.env/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 19)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.env/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.env/lib/python3.12/site-packages (from ipywidgets) (8.26.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.env/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.11 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.11 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in ./.env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.env/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.env/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.env/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.env/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.env/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.env/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.env/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.3 jupyterlab-widgets-3.0.11 widgetsnbextension-4.0.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "# Interactively ask for the user's input\n",
    "openai_key = input(\"Please enter your OpenAI API key: \")\n",
    "model_name_index = input(\"\"\"\n",
    "Please enter the index which corresponds with the name of the language model you wish to use. \n",
    "Your options are:\n",
    "[1] gpt-3.5-turbo\n",
    "[2] gpt-4o\n",
    "[3] gpt-4o-mini\n",
    "\"\"\".strip())\n",
    "model_name = {\n",
    "    \"1\": \"gpt-3.5-turbo\",\n",
    "    \"2\": \"gpt-4o\",\n",
    "    \"3\": \"gpt-4o-mini\"\n",
    "}[model_name_index]\n",
    "max_tokens = int(input(\"Please enter the maximum number of tokens you would like to generate: \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import set_up_dspy\n",
    "\n",
    "set_up_dspy(\n",
    "    openai_key=openai_key,\n",
    "    model_name=model_name,\n",
    "    max_tokens=max_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Tree-of-Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `State` instance\n",
    "\n",
    "A `State` (our framework's equivalent to a \"thought\") is a representation of the current state of a debate. It contains the following information:\n",
    "\n",
    "- `topic`: The topic of the argumentative conversation. For example, \"The US government should increase the national minimum wage.\"\n",
    "- `stance`: The stance of the debator towards the topic. Either 'PRO' or 'ANTI'. \n",
    "- `conversation`: The argumentative conversation. A list of strings, each representing a single persuasive argument. Note that \n",
    "    the stance of message `i` is opposite in stance to message `i+1`. \n",
    "\n",
    "**NOTE**: If you want the LLM-debator (i.e., the model that underlies the Tree-of-Thoughts) to generate an argument **without** a conversation as context (i.e., a single argument), set the `conversation` to `[]`.\n",
    "\n",
    "We provide you with a default 'State' object below. Feel free to modify it as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(topic='The US government should increase the national minimum wage', stance='PRO', conversation=['The US government is in a state of huge and nearly unpayable debt. Increasing the national minimum wage would only exacerbate this issue.'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tree import State\n",
    "\n",
    "# Define the initial state\n",
    "initial_state = State(\n",
    "    topic=\"The US government should increase the national minimum wage\",\n",
    "    stance=\"PRO\",\n",
    "    conversation=[\n",
    "        \"The US government is in a state of huge and nearly unpayable debt. Increasing the national minimum wage would only exacerbate this issue.\",      \n",
    "    ],\n",
    ")\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Abstractions\n",
    "\n",
    "**State**: \n",
    "- `State`: Represents the current state of the debate. Contains the topic, stance, and conversation.\n",
    "- `DraftState`: Extends `State` and contains additional information about previous drafts (given the same topic, stance, and conversation). The most recent draft was created by the parent node.\n",
    "\n",
    "**Node**:\n",
    "- `Node`: Wraps a `State` object. Contains additional information about the node's parent, children, the judge's score for the node, and the reasoning behind the score.\n",
    "- `TreeOfThoughtsNode`: Wraps a `DraftState` object. Contains additional information about the node's parent, children, the judge's score for the node, and the reasoning behind the score.\n",
    "\n",
    "**Edge**:\n",
    "- `Edge`: Represents a connection between two nodes. Contains the new argument (produced by the node of the source of the edge) and the reasoning behind that argument.\n",
    "\n",
    "**Tree**:\n",
    "- `Tree`: Represents a collection of nodes and edges that form a 'Tree of Thoughts'. Contains a dedicated field that points to the root node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a 'Tree-of-Thoughts' instance\n",
    "\n",
    "The Tree-of-Thoughts module utilizes two key components:\n",
    "\n",
    "1. `draft_predictor` (\"Thought Generator\"): A that creates a draft argument given the current state of the debate. \n",
    "2. `debate_judge` (\"States Evaluator\"): A module that evaluates the quality of an argument (either in the context of a conversation, or in isolation).\n",
    "\n",
    "You can decide whether or not to initialize these parameters with `chain_of_thoughts`, which on the one hand provides reasoning for outputs and tends to improve quality, but on the other hand increases computation time and cost.\n",
    "\n",
    "Moreover, you can specify the type of `debate_judge` you want to use (either `score` or `vote`). The `score` method evaluates each new argument in isolation, and provides a score. The `vote` method evaluates all of the new arguments at once, and then converts votes into scores.\n",
    "\n",
    "Finally, by specifying the `node_selection_strategy`, you can decide how the Tree-of-Thoughts selects the next argument to generate. The `random` strategy selects a collection of weighted random arguments, while the `best` strategy selects the arguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_of_thoughts import TreeOfThoughts\n",
    "\n",
    "tot_module = TreeOfThoughts(\n",
    "    use_chain_of_thought=True,\n",
    "    node_selection_strategy=\"greedy\",\n",
    "    evaluation_strategy=\"score\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Tree-of-Thoughts\n",
    "\n",
    "When running tree of thoughts, you can specify the following parameters:\n",
    "\n",
    "- `depth`: The maximum depth (number of layers) of the tree. Increasing the depth improves the nuances of generated arguments, but also increases computation time and cost.\n",
    "- `top_k`: The number of top arguments to select at each layer. Increasing the top_k arguments expands the search space, which can improve the quality of the generated arguments. However, it also increases computation time and cost.\n",
    "- `generation_temperature`: The temperature to use when generating arguments. A higher temperature results in more diverse arguments, while a lower temperature results in more conservative arguments.\n",
    "- `judge_temperature`: The temperature to use when evaluating arguments. A higher temperature results in more diverse evaluations, while a lower temperature results in more conservative evaluations.\n",
    "- `n_samples_generation`: The number of samples to generate for each argument. This parameter also increases the search space, but takes place before nodes are scored by the judge. That is, while `top_k` specifies the amount of judged arguments to keep, `n_samples_generation` specifies the amount of arguments to generate before judging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tot_module(\n",
    "    state=initial_state,\n",
    "    depth=2,\n",
    "    top_k=2,\n",
    "    generation_temperature=0.7,\n",
    "    judge_temperature=0.7,\n",
    "    n_samples_generation=3,\n",
    "    n_samples_judge=5,\n",
    "    response_length=\"a few sentences\",\n",
    ")\n",
    "print(f'\\n\\nThe response is:\\n\\n{response}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
